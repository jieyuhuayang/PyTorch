{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch1.0 在MNIST手写数字数据集上实现Logistic regression\n",
    "MNIST手写数字数据集：  \n",
    "可在 http://yann.lecun.com/exdb/mnist/ 获取,它包含了四个部分:  \n",
    "- Training set images: train-images-idx3-ubyte.gz (9.9 MB, 解压后 47 MB, 包含 **60,000 个样本**)  \n",
    "- Training set labels: train-labels-idx1-ubyte.gz (29 KB, 解压后 60 KB, 包含 **60,000 个标签**)  \n",
    "- Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 解压后 7.8 MB, 包含 **10,000 个样本**)  \n",
    "- Test set labels: t10k-labels-idx1-ubyte.gz (5KB, 解压后 10 KB, 包含 **10,000 个标签**)  \n",
    "\n",
    "Training/Testing set images 格式介绍： （其实torchvision包已经对数据加载进行优化,不用仔细研究数据格式啦）\n",
    "- offset:代表了**字节偏移量**  \n",
    "- type:属性的值的类型\n",
    "- value:属性的值\n",
    "- description:说明\n",
    "\n",
    "[offset] |[type]          |[value]          |[description] \n",
    "-------- | ------------------ |--------------------|--------- \n",
    "0000    | 32 bit integer  |0x00000803(2051) |magic number , 用于校验  \n",
    "0004    | 32 bit integer  |60000（训练集）/10000（测试集）   |   number of images \n",
    "0008    | 32 bit integer  |28            |   number of rows \n",
    "0012    | 32 bit integer  |28            |   number of columns \n",
    "0016    | unsigned byte   |??            |   pixel \n",
    "0017    | unsigned byte   |??           |   pixel \n",
    "........ | | |\n",
    "xxxx     |unsigned byte   |??           |    pixel  \n",
    "\n",
    "Training/Testing set labels 格式介绍：  \n",
    "\n",
    "[offset]    | [type]       |[value]          |[description] \n",
    "-------- | ------------------ |--------------------|---------  \n",
    "0000    |  32 bit integer | 0x00000801(2049) |magic number (MSB first), 用于校验  \n",
    "0004    | 32 bit integer  |60000(训练集)/1000(测试集)    |  number of items   \n",
    "0008    | unsigned byte   |??            |   label(0到9)   \n",
    "0009    | unsigned byte   |??            |   label(0到9) \n",
    "........ |            |               |  \n",
    "xxxx    | unsigned byte  | ??             |  label(0到9)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hyper-parameters 设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 超参数设置 Hyper-parameters\n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MINIST数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train (bool, optional): If True, creates dataset from ``training.pt``,otherwise from ``test.pt``\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../../data/minist',train=True,transform=transforms.ToTensor(),download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='../../../data/minist',train=False,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据加载器\n",
    "torch.utils.data.DataLoader  \n",
    "> ```python\n",
    "torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=<function default_collate>, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None)```\n",
    "\n",
    "Parameters参数:\t\n",
    "- dataset (Dataset) – dataset from which to load the data.  \n",
    "- batch_size (int, optional) – how many samples per batch to load **(default: 1)**.\n",
    "- shuffle (bool, optional) – set to True to have the data reshuffled at every epoch每个epoch数据打乱 (default: False).\n",
    "- sampler (Sampler, optional) – defines the strategy to draw samples from the dataset. If specified, shuffle must be False.\n",
    "- batch_sampler (Sampler, optional) – like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.\n",
    "- num_workers (int, optional) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)\n",
    "- collate_fn (callable, optional) – merges a list of samples to form a mini-batch.\n",
    "- pin_memory (bool, optional) – If True, the data loader will copy tensors into CUDA pinned memory before returning them.\n",
    "- drop_last (bool, optional) – set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)\n",
    "- timeout (numeric, optional) – if positive, the timeout value for collecting a batch from workers. Should always be non-negative. (default: 0)\n",
    "- worker_init_fn (callable, optional) – If not None, this will be called on each worker subprocess with the worker id (an int in [0, num_workers - 1]) as input, after seeding and before data loading. (default: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载器（data loader）\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "\n",
    "#for i,(images,labels)in enumerate(train_loader):\n",
    "#    if(i%100==0):\n",
    "#        print(images.size(),labels)\n",
    "\n",
    "    \n",
    "#print(type(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PyTorch中的CrossEntropyLoss交叉熵损失函数介绍\n",
    "```torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')```  \n",
    "- This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
    "- It is useful when training a classification problem with C classes.  \n",
    "- The input is expected to contain scores for each class.\n",
    "- This criterion expects a class index (0 to C-1) as the target for each value of a 1D tensor of size minibatch  \n",
    "\n",
    "公式：\n",
    "$\\operatorname{loss}(x,$class$)=-\\log \\left(\\frac{\\exp (x[\\text {class}])}{\\sum_{j} \\exp (x[j])}\\right)=-x[$class$]+\\log \\left(\\sum_{j} \\exp (x[j])\\right)$  \n",
    "- $x[\\text {class}]$:给实际类的打分\n",
    "- x 的形状：(N, C)where C = number of classes\n",
    "- class 的形状：(N) where each value is $0 \\leq \\text{targets}[i] \\leq C-10≤targets[i]≤C−1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression模型定义及训练 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1/600], Loss: 2.3466\n",
      "Epoch [1/5], Step [101/600], Loss: 2.2670\n",
      "Epoch [1/5], Step [201/600], Loss: 2.1388\n",
      "Epoch [1/5], Step [301/600], Loss: 2.0264\n",
      "Epoch [1/5], Step [401/600], Loss: 1.9344\n",
      "Epoch [1/5], Step [501/600], Loss: 1.8658\n",
      "Epoch [2/5], Step [1/600], Loss: 1.8553\n",
      "Epoch [2/5], Step [101/600], Loss: 1.7081\n",
      "Epoch [2/5], Step [201/600], Loss: 1.7209\n",
      "Epoch [2/5], Step [301/600], Loss: 1.6017\n",
      "Epoch [2/5], Step [401/600], Loss: 1.5479\n",
      "Epoch [2/5], Step [501/600], Loss: 1.5100\n",
      "Epoch [3/5], Step [1/600], Loss: 1.5170\n",
      "Epoch [3/5], Step [101/600], Loss: 1.4937\n",
      "Epoch [3/5], Step [201/600], Loss: 1.4455\n",
      "Epoch [3/5], Step [301/600], Loss: 1.4116\n",
      "Epoch [3/5], Step [401/600], Loss: 1.4038\n",
      "Epoch [3/5], Step [501/600], Loss: 1.3281\n",
      "Epoch [4/5], Step [1/600], Loss: 1.2757\n",
      "Epoch [4/5], Step [101/600], Loss: 1.2151\n",
      "Epoch [4/5], Step [201/600], Loss: 1.1528\n",
      "Epoch [4/5], Step [301/600], Loss: 1.1582\n",
      "Epoch [4/5], Step [401/600], Loss: 1.1666\n",
      "Epoch [4/5], Step [501/600], Loss: 1.0810\n",
      "Epoch [5/5], Step [1/600], Loss: 1.2833\n",
      "Epoch [5/5], Step [101/600], Loss: 1.0939\n",
      "Epoch [5/5], Step [201/600], Loss: 1.1018\n",
      "Epoch [5/5], Step [301/600], Loss: 0.9825\n",
      "Epoch [5/5], Step [401/600], Loss: 1.0706\n",
      "Epoch [5/5], Step [501/600], Loss: 1.0025\n"
     ]
    }
   ],
   "source": [
    "# 定义逻辑回归模型\n",
    "class LR(nn.Module):\n",
    "    def __init__(self,input_dims,output_dims):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(input_dims, output_dims,bias=True)\n",
    "    def forward(self,x):\n",
    "        x=self.linear(x)\n",
    "        return x\n",
    "        \n",
    "LR_model=LR(input_size, num_classes)\n",
    "\n",
    "# 定义逻辑回归的损失函数，采用nn.CrossEntropyLoss(),nn.CrossEntropyLoss()内部集成了softmax函数\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "# 定义optimizer\n",
    "optimizer=torch.optim.SGD(LR_model.parameters(),lr=learning_rate)\n",
    "\n",
    "# 训练模型\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels)in enumerate(train_loader):\n",
    "         # 将图像序列转换至大小为 (batch_size, input_size),应为（100，,784）\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        \n",
    "        \n",
    "        # forward\n",
    "        y_pred = LR_model(images)\n",
    "        #print(y_pred.size())\n",
    "        #print(labels.size())\n",
    "        loss = criterion(y_pred,labels)\n",
    "        \n",
    "        # backward()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i%100==0):\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 82 %\n"
     ]
    }
   ],
   "source": [
    "# 在测试阶段，为了运行内存效率，就不需要计算梯度了\n",
    "# PyTorch 默认每一次前向传播都会计算梯度\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = LR_model(images)\n",
    "        # torch.max的输出：out (tuple, optional) – the result tuple of two output tensors (max, max_indices)\n",
    "        max, predicted = torch.max(outputs.data, 1)\n",
    "        #print(max.data)\n",
    "        #print(predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 保存模型\n",
    "torch.save(LR_model.state_dict(), 'model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
